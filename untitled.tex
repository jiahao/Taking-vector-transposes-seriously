\section{Definitions of the transpose}

Let's have a look at how the matrix transpose is defined in the mathematical literature.

\cite[p. 280, Definition 10]{Gantmacher1960} defines the transpose to have the following properties:

For a linear operator $A$ over $\mathbb R^n$,

the transpose $A^T$ is the operator such that for any two vectors $x, y \in \mathbb R^n$,

\[
\left\langle Ax, y \right\rangle = \left\langle x, A^T y \right\rangle
\]

and has the properties

\begin{align}

(A^T)^T & = A \\
(A + B)^T & = A^T + B^T \\
(\alpha A)^T & = \alpha A^T \text{ for all real numbers } \alpha \\
(A B)^T & = B^T A^T

\end{align}

Analogous definitions and properties for the $A^*$, the adjoint of $A$ (for operators over unitary space $\mathbb C^n$), appear on p. 266.

Gantmacher never uses the terms ``row vector'' or ``column vector'', but defines row and column matrices as matrices having only one row or column respectively. Vectors are defined only as elements of a vector space \cite[p. 51]{Gantmacher1960}, having the usual axiomatic properties of vector spaces over a field $\mathbb F$ and addition and multiplication. He then defines a column as a $n$-tuple of numbers (p. 51, Example 2), $\mathbb F^n$, and shows that operations defined as ``operations on column matrices'' fulfill the axioms of a vector space.

Gantmacher also distinguishes \cite[pp. 54-56]{Gantmacher1960} between the linear operator $A$ and its matrix representation $A$, saying that the $k$th column of the matrix ``consists of the coordinates of the vector $Ae_k$''.

``If in an $n$-dimensional space a basis $\mathbf e_1, \mathbf e_2, \dots, \mathbf e_n$ has been chosen, then to every vector $\mathbf x$ there corresponds uniquely the column $x = (x_1, x_2, \dots, \mathbf x_n)$ where $x_1, x_2, \dots, \mathbf x_n$ are the coordinates of $\mathbf x$ in the given basis. Thus, the choosing of a basis establishes a one-to-one correspondence between the vectors of an arbitrary $n$-dimensional vector space $\mathbf R$ and the vectors of the $n$-dimensional number space $\mathbb F^n$... This means that to within isomorphism there exists only one $n$-dimensional vector space of a given number field.''

The fuss over the abstractions of vector space may seem fussy, but in fact it the definition of matrix multiplication arises naturally from the composition of linear operators, and is correct independent of basis. The notion of basis-independent properties is what is often neglected in computer representations, as is the notion of ``up to isomorphism'' as described by Gantmacher.