\section{Linear algebra can be represented with arrays in many different ways}

Problems arise when trying to implement linear algebra on arrays, which are data structures defined by their indexing behavior. In particular, array data structures have a specific dimensionality specifying the number of indexes needed to address elements in the array~\footnote{The array is such a fundamental data structure that it is difficult to pin down a concrete definition. Nevertheless, the early implementations of arrays in languages such as FORTRAN~\cite[p36]{Backus1956} and ALGOL~60~\cite[Sec. 2.3]{Randell1964} make clear that indexing by a fixed number of integers is the most primitive operation associated with an array.}. While in the mathematical literature the distinction between ``column vector'' and ``column matrix'' is often glossed over, these terms now refer to two different possible representations as one- and two-dimensional arrays respectively. If a column vector can be represented as a one-dimensional array, there is also the question of whether ``row vectors'' can be meaningfully represented using one-dimensional arrays also. Furthermore, there is the question of whether a scalar product, by analogy with matrix multiplication, should return a true scalar (a 0-dimensional array) or a $1\times1$ matrix (a two-dimensional array).

It turns out that various programming languages and libraries used for numerical computing implement many different approaches to the problem of representing vectors.